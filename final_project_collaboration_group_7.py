# -*- coding: utf-8 -*-
"""Final_Project_Collaboration_Group 7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lipWGYZPBh8DdOuGYqPFfnM9c1Uy1Bgv
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import json
from typing import Any, Dict, List
import datetime
from pathlib import Path

"""## Data Acquisition and Loading

National Vulnerability Database (NVD)
"""

# NVD Data Loading
def process_nvd_json(file_path: str) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Process an NVD JSON file and convert it to two normalized DataFrames:
    1. Main CVE DataFrame
    2. CPE matches DataFrame with foreign key to CVE

    Args:
        file_path (str): Path to the NVD JSON file

    Returns:
        tuple[pd.DataFrame, pd.DataFrame]: Tuple containing (cve_df, cpe_df)
    """
    # Read the JSON file
    with open(file_path, 'r', encoding = 'ISO-8859-1') as f:
        nvd_data = json.load(f)

    # Lists to store processed items
    cve_items = []
    cpe_items = []

    for cve_item in nvd_data['CVE_Items']:
        cve_data = {}

        # Basic CVE information
        cve_id = cve_item['cve']['CVE_data_meta']['ID']
        cve_data['id'] = cve_id
        cve_data['assigner'] = cve_item['cve']['CVE_data_meta']['ASSIGNER']
        cve_data['published_date'] = cve_item['publishedDate']
        cve_data['last_modified_date'] = cve_item['lastModifiedDate']

        # Description
        descriptions = cve_item['cve']['description']['description_data']
        cve_data['description'] = next((desc['value'] for desc in descriptions if desc['lang'] == 'en'), '')

        # Problem type (CWE)
        try:
            problemtype_data = cve_item['cve']['problemtype']['problemtype_data']
            if problemtype_data and problemtype_data[0]['description']:
                cve_data['cwe'] = problemtype_data[0]['description'][0].get('value', '')
            else:
                cve_data['cwe'] = ''
        except (KeyError, IndexError):
            cve_data['cwe'] = ''

        # References
        try:
            references = cve_item['cve']['references']['reference_data']
            cve_data['references'] = '; '.join(ref['url'] for ref in references)
        except (KeyError, IndexError):
            cve_data['references'] = ''

        # CVSS v3 metrics
        try:
            cvss3 = cve_item['impact']['baseMetricV3']['cvssV3']
            cve_data['cvss3_vector'] = cvss3.get('vectorString', '')
            cve_data['cvss3_base_score'] = cvss3.get('baseScore', None)
            cve_data['cvss3_base_severity'] = cvss3.get('baseSeverity', '')
            cve_data['attack_vector'] = cvss3.get('attackVector', '')
            cve_data['attack_complexity'] = cvss3.get('attackComplexity', '')
            cve_data['privileges_required'] = cvss3.get('privilegesRequired', '')
            cve_data['user_interaction'] = cvss3.get('userInteraction', '')
            cve_data['scope'] = cvss3.get('scope', '')
            cve_data['confidentiality_impact'] = cvss3.get('confidentialityImpact', '')
            cve_data['integrity_impact'] = cvss3.get('integrityImpact', '')
            cve_data['availability_impact'] = cvss3.get('availabilityImpact', '')
        except (KeyError, TypeError):
            cve_data.update({
                'cvss3_vector': '',
                'cvss3_base_score': None,
                'cvss3_base_severity': '',
                'attack_vector': '',
                'attack_complexity': '',
                'privileges_required': '',
                'user_interaction': '',
                'scope': '',
                'confidentiality_impact': '',
                'integrity_impact': '',
                'availability_impact': ''
            })

        # Process CPE matches
        try:
            nodes = cve_item['configurations']['nodes']
            for node in nodes:
                if 'cpe_match' in node:
                    for cpe in node['cpe_match']:
                        cpe_info = {
                            'cve_id': cve_id,
                            'cpe23Uri': cpe.get('cpe23Uri', ''),
                            'vulnerable': cpe.get('vulnerable', False),
                            'versionStartIncluding': cpe.get('versionStartIncluding', ''),
                            'versionEndIncluding': cpe.get('versionEndIncluding', ''),
                            'versionStartExcluding': cpe.get('versionStartExcluding', ''),
                            'versionEndExcluding': cpe.get('versionEndExcluding', '')
                        }

                        # Parse CPE URI into components
                        cpe_parts = cpe_info['cpe23Uri'].split(':')
                        if len(cpe_parts) > 4:
                            cpe_info.update({
                                'vendor': cpe_parts[3],
                                'product': cpe_parts[4],
                                'version': cpe_parts[5]
                            })

                        cpe_items.append(cpe_info)
        except (KeyError, TypeError):
            pass

        cve_items.append(cve_data)

    # Create DataFrames
    cve_df = pd.DataFrame(cve_items)
    cpe_df = pd.DataFrame(cpe_items)

    # Convert date columns to datetime
    date_columns = ['published_date', 'last_modified_date']
    for col in date_columns:
        cve_df[col] = pd.to_datetime(cve_df[col])

    # Sort DataFrames
    cve_df = cve_df.sort_values('id')
    cpe_df = cpe_df.sort_values(['cve_id', 'cpe23Uri'])
    return cve_df, cpe_df


# Replace with your file name and path
file_path_2023 = "/content/drive/MyDrive/BIT3474GroupProject/data/nvdcve-1.1-2023.json"
file_path_2022 = "/content/drive/MyDrive/BIT3474GroupProject/data/nvdcve-1.1-2022.json"
file_path_2024 = "/content/drive/MyDrive/BIT3474GroupProject/data/nvdcve-1.1-2024.json"

try:
    # Process the NVD JSON file
    cve_df_2023, cpe_df_2023 = process_nvd_json(file_path_2023)
    cve_df_2022, cpe_df_2022 = process_nvd_json(file_path_2022)
    cve_df_2024, cpe_df_2024 = process_nvd_json(file_path_2024)

    # Optionally save to CSV
    cve_df_2023.to_csv('processed_cve_data.csv', index=False)
    cpe_df_2023.to_csv('processed_cpe_data.csv', index=False)
    cve_df_2022.to_csv('processed_cve_data.csv', index=False)
    cpe_df_2022.to_csv('processed_cpe_data.csv', index=False)
    cve_df_2024.to_csv('processed_cve_data.csv', index=False)
    cpe_df_2024.to_csv('processed_cpe_data.csv', index=False)

except FileNotFoundError:
    print(f"Error: File '{file_path_2023}' not found.")
    print(f"Error: File '{file_path_2022}' not found.")
    print(f"Error: File '{file_path_2024}' not found.")
except json.JSONDecodeError:
    print("Error: Invalid JSON file format.")
except Exception as e:
    print(f"Error processing file: {str(e)}")

# Concatenating all three NVD DataFrames into one DataFrame
nvd_df = pd.concat([cve_df_2024, cve_df_2023, cve_df_2022], axis=0, ignore_index=True)

# The accumulated first attempt of the NVD DataFrame
nvd_df

# Choosing the preferred NVD columns to be stored for the final merged dataframe
nvd_selected_columns = ['id', 'published_date', 'last_modified_date', 'description', 'cwe', 'cvss3_base_score', 'cvss3_base_severity']
nvd_df = nvd_df[nvd_selected_columns]

# Renaming each of the preferred columns to be readable for anyone
nvd_df.rename(columns={'id': 'CVE ID', 'published_date': 'Published Date', 'last_modified_date': 'Last Modified Date', 'description': 'Description', 'cwe': 'CWE ID', 'cvss3_base_score': 'CVSS3 Base Score', 'cvss3_base_sevirity': 'CVSS3 Base Sevirity'}, inplace=True)

# The final NVD DataFrame
nvd_df

"""Known Exploited Vulnerabilities (KEV)"""

# KEV Data Loading
kev_file_path = 'https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json'
kev_request = requests.get(kev_file_path)
kev_read = kev_request.json()
kev_df = pd.DataFrame(kev_read['vulnerabilities'])

# Removing any unnecessary columns for the last dataframe
kev_df = kev_df.drop(['knownRansomwareCampaignUse', 'dueDate'], axis=1)

# Renaming the columns to be more accessible
kev_df.rename(columns={'cveID': 'CVE ID', 'vendorProject': 'Vendor Projected', 'product': 'Product', 'vulnerabilityName': 'Vulnerability Name', 'dateAdded': 'Date Added', 'shortDescription': 'Short Description', 'requiredAction': 'Required Action', 'dueDate': 'Due Date', 'notes': 'Notes', 'cwes': 'CWES ID'}, inplace=True)

# Converting the date columns to datetime
kev_date_columns = ['Date Added']
for col in kev_date_columns:
    kev_df[col] = pd.to_datetime(kev_df[col])

# Sorting the KEV DataFrame
kev_df = kev_df.sort_values('CVE ID')
kev_df = kev_df.reset_index(drop=True)

# The final KEV DataFrame
kev_df

"""Common Weakness Enumeration (CWE)"""

# CWE Data Loading
def comprehensive_field_extractor(data):
    """
    Extract all fields from CWE weakness data, including nested fields stored as separate columns.

    :param data: Raw CWE weakness data
    :return: Flattened dictionary of all extractable fields
    """
    flattened = {}

    # Core weakness fields
    core_fields = [
        'ID', 'Name', 'Abstraction', 'Structure',
        'Status', 'Description', 'ExtendedDescription', 'LikelihoodOfExploit', 'BackgroundDetails'
    ]
    for field in core_fields:
        flattened[field] = data.get(field, 'N/A')

    # Complex nested fields
    # ApplicablePlatforms
    flattened['Platforms'] = ', '.join([
        f"{p.get('Type', '')}: {p.get('Class', '')}"
        for p in data.get('ApplicablePlatforms', [])
    ])

    # CommonConsequences (split into separate columns)
    common_consequences = data.get('CommonConsequences', [])
    for i, consequence in enumerate(common_consequences):
        flattened[f'Consequence_{i+1}_Scope'] = consequence.get('Scope', 'N/A')
        flattened[f'Consequence_{i+1}_Impact'] = consequence.get('Impact', 'N/A')

    # ObservedExamples (split into separate columns)
    observed_examples = data.get('ObservedExamples', [])
    for i, example in enumerate(observed_examples):
        flattened[f'ObservedExample_{i+1}_Reference'] = example.get('Reference', 'N/A')
        flattened[f'ObservedExample_{i+1}_Description'] = example.get('Description', 'N/A')

    # References (split into separate columns)
    references = data.get('References', [])
    for i, reference in enumerate(references):
        flattened[f'Reference_{i+1}_Title'] = reference.get('Title', 'N/A')
        flattened[f'Reference_{i+1}_URL'] = reference.get('URL', 'N/A')  # Add more fields if needed

    return flattened

cwe_file_path = 'https://cwe-api.mitre.org/api/v1/cwe/weakness/all'
cwe_response = requests.get(cwe_file_path)

# If the file path was successful, then the raw JSON data will be extracted and
# used in the function comprehensive_field_extractor
if cwe_response.status_code == 200:
    cwe_raw_data = cwe_response.json()  # Extract JSON data
else:
    print(f"Error: Failed to retrieve CWE data (Status Code: {cwe_response.status_code})")
    exit()

data = cwe_response.json()

flattened_weaknesses = [
        comprehensive_field_extractor(weakness)
        for weakness in data.get("Weaknesses", [])
    ]


# Creating the CWE DataFrame from the CWE column "Weaknesses"
cwe_df = pd.DataFrame(cwe_raw_data.get("Weaknesses"))
csv_filename = "cwe_data.csv"
cwe_df.to_csv(csv_filename, index=False)

# Selecting the required CWE columns within "Weaknesses"
select_cwe_columns = ['ID', 'Name', 'Description', 'TaxonomyMappings']
cwe_df = cwe_df[select_cwe_columns]
cwe_df = cwe_df.rename(columns={'ID': 'CWE ID', 'Name': 'CWE Name', 'Description': 'CWE Description', 'TaxonomyMappings': 'Taxonomy Mappings'})

# The first attempt of the CWE DataFrame
cwe_df

# After noticing the CWE ID column only had numbers, we decided to add "CWE-"
# to each number to clarify and identify where the numbers came from
cwe_df['CWE ID'] = cwe_df['CWE ID'].apply(lambda x: 'CWE-' + str(x))
cwe_df

"""## Data Cleaning and Transformation


"""

# The first merge dataframe was between the NVD DataFrame and the
# KEV Catalog DataFrame
merged_df = pd.merge(nvd_df, kev_df, on='CVE ID', how='left')
merged_df

# The last part of the merge was including the CWE DataFrame as well
merged_df = pd.merge(merged_df, cwe_df, on='CWE ID', how='left')

# The final merged dataframe from all three stored dataframes
merged_df

# Calculating the vulnerability age (time elapsed since
# vulnerability disclosure)

# Make the Published Date column in datetime format and timezone-naive
merged_df['Published Date'] = pd.to_datetime(merged_df['Published Date']).dt.tz_localize(None)

# Calculate the vulnerability age
merged_df['Vulnerability Age'] = (pd.Timestamp.now().tz_localize(None) - merged_df['Published Date']).dt.days

merged_df['is_exploited'] = merged_df['Date Added'].notnull()

merged_df

"""## Exploratory Data Analysis and Visualization"""

plt.figure(figsize=(10, 5))

# Histogram

plt.subplot(1, 2, 1) # Select 1st plot
sns.histplot(data=nvd_df, x="CVSS3 Base Score", bins=8, kde=False)
plt.title("Histogram CVSS v3 Score for Vulnerabilities")
plt.xlabel("CVSS v3 Score")
plt.ylabel("Frequency (Count)")

plt.subplot(1, 2, 2) # Select 2nd plot
sns.histplot(data=nvd_df, x="CVSS3 Base Score", bins=8, kde=True)
plt.title("Histogram CVSS v3 Score for Vulnerabilities with KDE")
plt.xlabel("CVSS v3 Score")
plt.ylabel("Frequency (Count)")

plt.tight_layout()
plt.show()

"""The histogram visualization shows that the typical severity of vulnerabilities is skewed high towards higher values. There is a wide range from 2-10. Higher severity scores are more common than lower serverity scores."""

nvd_df["month"] = nvd_df["Published Date"].dt.to_period("M")

# SMART Goal 1: Throughout the year 2022, has there been a percentage increase greater than 10% in the
# number of exploited vulnerabilities globally since February 24, 2022?

monthly_count = (nvd_df
                 .groupby('month')
                 ['CVE ID'].count()
                 .reset_index(name="monthly_total")
                 )

monthly_count['month'] = monthly_count['month'].astype(str)

plt.figure(figsize=(15, 6))
sns.lineplot(data=monthly_count.head(12), x='month', y='monthly_total', marker='o')


plt.title('Vulnerabilities Published in 2022')
plt.xlabel('Month')
plt.ylabel('# of Vulnerabilities Published')
plt.ylim(bottom=0)
plt.show()

"""The first three months of 2022 had a significant increase greater than 10% in the number of vulnerabilities published. This is because of the tension and reignition of the Russo-Ukrainian War when Russia invaded Ukraine on February 24, 2022. After March, the increase began to level off until September, when publications decreased. Since then, the graph of vulnerabilities has increased and decreased for the remaining months of 2022. The peak months in the time series plot were October and December."""

plt.figure(figsize=(15, 5))

# Box Plot
plt.subplot(1, 2, 1)
sns.boxplot(data=merged_df[merged_df['is_exploited'] == True], x="CVSS3 Base Score")
plt.title("Distribution of CVSS v3 Score for Exploited Vulnerabilities (Box Plot)")
plt.xlabel("CVSS v3 Score")
plt.ylabel("Exploited Vulnerabilities (Count)")

# Violin Plot
plt.subplot(1, 2, 2)
sns.violinplot(data=merged_df[merged_df['is_exploited'] == False], x="CVSS3 Base Score")
plt.title("Distribution of CVSS v3 Score for Non-Exploited Vulnerabilities (Violin Plot)")
plt.xlabel("CVSS v3 Score")
plt.ylabel("Non-exploited Vulnerabilities (Count)")

plt.tight_layout()
plt.show()

"""The non-exploited vulnerabilities violin plot shows the highest probabilities of severity in the range of 5.5 to 10. The exploited vulnerabilities box plot's interquartile range is between 7.5 and 9.8, which is much tighter and higher in severity than the violin plot.

## Descriptive Statistics
"""

# SMART Goal 2: What have been the mean Common Vulnerability Scoring System 3 (CVSS3)
# base scores across the NVD, the KEV Catalog, and the CWE from January 1, 2022,
# to December 31, 2024?

merged_df['Published Date'] = pd.to_datetime(merged_df['Published Date'])

start_date = '2022-01-01'
end_date = '2024-12-31'

filtered_df = merged_df[(merged_df['Published Date'] >= start_date) & (merged_df['Published Date'] <= end_date)]

print('The mean CVSS3 Base Score across all three databases from January 1, 2022 to December 31, 2024 is', float(filtered_df['CVSS3 Base Score'].mean()))

# All of the discovered CVSS Scores
cvss_stats = {
    'Mean': float(nvd_df['CVSS3 Base Score'].mean()),
    'Median': nvd_df['CVSS3 Base Score'].median(),
    'Standard Deviation': nvd_df['CVSS3 Base Score'].std()
}
cvss_stats

# The accumulated number of vulnerabilities per year in the NVD DataFrame
vulnerabilities_each_year = nvd_df.groupby(nvd_df['Published Date'].dt.year)['CVE ID'].count()
vulnerabilities_each_year

# The total number of vulnerabilites per CWE category
cwe_count = merged_df['CWE ID'].value_counts()
cwe_count

# The count of known CWE vulnerabilities
exploited_by_cwe = merged_df[merged_df['is_exploited'] == True].groupby('CWE ID').size().reset_index(name='Exploited Count')
exploited_by_cwe

"""## Exploratory Inferences"""

# SMART Goal 3: What software product has had the highest number of
# security vulnerabilities between 2022 and 2024?

merged_df['Published Date'] = pd.to_datetime(merged_df['Published Date'])

start_date = '2022-01-01'
end_date = '2024-12-31'

filtered_df = merged_df[(merged_df['Published Date'] >= start_date) & (merged_df['Published Date'] <= end_date)]

software_counts = filtered_df['Product'].value_counts()

most_exposed_product = software_counts.idxmax()
most_exposed_count = software_counts.max()

print('The software product with the highest number of vulnerabilities between 2022 and 2024'
'\n was', most_exposed_product, 'with', most_exposed_count, 'vulnerabilities')

# Vulnerable software categories and their associated CWE weaknesses
software_cwe = merged_df.groupby(['Product', 'CWE ID']).size().reset_index(name='count')
software_cwe_sorted = software_cwe.sort_values(by='count', ascending=False)
software_cwe_sorted.head(10)

# Evaluating the impact of CVSS score on vulnerability exploitation
cvss_impact = merged_df[['CVSS3 Base Score', 'is_exploited']].groupby('is_exploited').describe().round(2)

cvss_impact[('CVSS3 Base Score', 'count')] = cvss_impact[('CVSS3 Base Score', 'count')].astype(int)
cvss_impact = cvss_impact.drop([('CVSS3 Base Score', 'std'), ('CVSS3 Base Score', '25%'), ('CVSS3 Base Score', '50%'), ('CVSS3 Base Score', '75%')], axis=1)

cvss_impact

"""The data describes the cvss3 base scores based on whether the CVE was exploited or not exploited using the KEV catalog. It concludes that the higher the cvss3 score, the higher the probability of it being exploited.

Reasons:
* The exploited CVEs (True) have a higher average cvss3 score (8.40) than the non-exploited CVEs (False) average cvss3 score (7.05).
* According to the data, most CVEs aren't exploited (393 vs. 67,795), but if the CVE was exploited, they will generally have a higher cvss3 score.
* Although both have some max scores of 10, the exploited CVEs generally start at a higher number (2.7) than the non-exploited CVEs (1.9).
"""

# Box Plot representation on Vulnerability Exploitation
sns.boxplot(data=merged_df, x='is_exploited', y='CVSS3 Base Score')

plt.xticks([0, 1], ['Not Exploited', 'Exploited'])
plt.xlabel('Exploitation Status')
plt.ylabel('CVSS v3 Base Score')
plt.title('CVSS Score Distribution by Exploitation (KEV)')
plt.tight_layout()
plt.show()

"""This is a visual representation of a box plot comparing the exploitation of the CVSS scores. The non-exploited scores have a wider interquartile range with most values being approximately between 5.0 and 9.0. In addition, the median is much lower than the exploited scores. The exploited scores have a higher median, but the interquartile range is more narrow, with most values being approximately between 7.0 and 10.0."""

# Determining potential risk factors based on vulnerability trends and CWE analysis.
grouped = merged_df.groupby(['Product', 'CWE Name']).size().reset_index(name='Count')
top_products = merged_df['Product'].value_counts().nlargest(6).index
filtered = merged_df[merged_df['Product'].isin(top_products)]

# Limit to most common 10 CWE types for each product
top_cwes = filtered['CWE Name'].value_counts().nlargest(10).index
filtered = filtered[filtered['CWE Name'].isin(top_cwes)]

# Plot using catplot
sns.set(style="whitegrid", palette="muted")
g = sns.catplot(
    data=filtered,
    x="CWE Name",
    kind="count",
    hue="cvss3_base_severity",
    col="Product",
    col_wrap=3,
    height=5,
    aspect=1.5
)

g.set_xticklabels(rotation=45, horizontalalignment='right')
g.set_titles("{col_name}")
g.fig.subplots_adjust(top=0.9)
g.fig.suptitle("Top CWE Weaknesses by Product Category and Severity")

plt.show()